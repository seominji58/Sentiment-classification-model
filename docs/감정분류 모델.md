# 감정 분류 모델 개발 문서

## 문서 목적
이 문서는 프로젝트 전체 파이프라인 구조, 학습 흐름, 품질 확보 원칙을 정리한 개발 리드 문서입니다. 신규 팀원이 구조를 파악하거나 설계 결정을 검토할 때 참고하도록 작성되었습니다.

## 프로젝트 개요
- 감성대화 데이터(`merged.csv`)를 전처리해 5개 주요 감정(행복·평온·불안·분노·슬픔)으로 라벨링합니다.
- Colab 의존 없이 로컬/서버 환경에서 재현 가능한 파일 기반 파이프라인을 제공합니다.
- Baseline(LinearSVC)과 Transformer 모델을 모두 포함하여 실험/비교가 가능하도록 설계했습니다.

## 디렉터리 구조
```
emotion-model/
├── configs/            # 하이퍼파라미터, 라벨 매핑, 규칙 정보
├── data/               # 원본 데이터 (버전 관리 제외 권장)
├── docs/               # 문서 및 디자인 노트
├── processed/          # 전처리 결과, 분할 데이터, 모델 산출물
├── scripts/            # 파이프라인 엔트리 포인트
├── src/                # 파이프라인 모듈 및 유틸
├── tests/              # 단위 테스트
└── requirements.txt
```

## 실행 환경
- Python 3.11, Miniconda 가상환경 권장
- 필수 패키지: `pandas`, `scikit-learn`, `transformers`, `torch`, `datasets`, `tqdm`, `joblib`
- 설치 예시:
  ```bash
  conda create -n saegim python=3.11 -y
  conda activate saegim
  pip install -r requirements.txt
  ```

## 설계 원칙
- **단일 진실원**: 라벨 매핑, 규칙은 `configs/config.json` 하나에서 관리합니다.
- **명시적 검증**: `src/utils.py`의 `ensure_columns`, `must_not_empty` 등으로 단계별 전처 조건을 확인합니다.
- **재현성**: `utils.set_seed`로 시드를 고정하고, 산출물은 `processed/`에 일관되게 저장합니다.
- **모듈화**: 데이터 처리, 라벨 매핑, 분할, 모델 학습, 평가를 개별 모듈로 나누어 유지보수가 쉽도록 구성했습니다.

## 파이프라인 단계
| 단계 | 모듈 | 설명 | 입력 | 출력 |
|------|------|------|------|------|
| 1 | `src/data_io.py` | CSV 로드 및 기본 검증 | `data/merged.csv` | `merged_df` |
| 2 | `src/preprocess.py` | 텍스트 정제, 중복/결측 제거 | `merged_df` | `cleaned_df` |
| 3 | `src/label_map.py` | 감정 코드 → 5개 감정 매핑 | `cleaned_df` | `final_df` |
| 4 | `src/split.py` | Stratified 90/10 데이터 분할 | `final_df` | `train.csv`, `valid.csv` |
| 5 | `src/anomaly.py` | TF-IDF 기반 이상치 검토 | `train.csv` | `anomaly_suspicious.csv` |
| 6 | `src/baseline.py` | TF-IDF + LinearSVC 학습/검증 | `train/valid` | baseline metrics |
| 7 | `src/transformer.py` | Hugging Face Trainer 기반 파인튜닝 | `train/valid` | transformer model |
| 8 | `src/evaluation.py` | confusion matrix, 리포트 생성 | `valid` | advanced metrics |

`scripts/run_all.py`는 위 단계를 순차 실행합니다. 필요 시 각 단계별 스크립트를 단독으로 호출할 수 있습니다.

## 공용 유틸 (`src/utils.py`)
- `set_seed`, `mark_ok`, `require`로 파이프라인 상태를 관리합니다.
- `ensure_columns`, `must_not_empty`로 데이터 유효성을 선제적으로 확인합니다.
- `save_csv`, `log_step`으로 산출물 기록과 로그 일관성을 유지합니다.

## 모델 학습 흐름
1. `scripts/train_transformer.py` 실행 → 설정 로드 및 시드 고정
2. 훈련/검증 CSV 로드 → `Dataset` 변환 → 토크나이징
3. 클래스 가중치 계산(불균형 완화) → `WeightedTrainer` 구성
4. 학습/평가 실행 → 체크포인트 및 최종 모델 저장
5. `processed/models/transformer/metrics.json`에 정확도, macro-F1, runtime 기록

Baseline 학습은 `scripts/train_baseline.py`로 진행하며, 비교를 위해 같은 분할 데이터를 사용합니다.

## 평가 지표 및 산출물
- Accuracy, Macro-F1, 클래스별 Precision/Recall, Confusion Matrix
- 저장 경로:
  - `processed/models/baseline/metrics.json`
  - `processed/models/transformer/metrics.json`
  - 추가 리포트는 `processed/models/*/` 하위에 생성

## 완성 기준 체크리스트
- 모든 단계가 오류 없이 완료되고 `processed/`에 산출물이 생성됐는가?
- Transformer 모델이 baseline 대비 Macro-F1에서 향상되었는가?
- 동일 데이터로 학습을 반복했을 때 결과가 재현되는가?

## 향후 개선 로드맵 (실무 관점)
1. **불균형 해소 실험**: 클래스 가중치 외에 데이터 증강, 재표본 전략을 도입하고, 소수 감정 F1 모니터링 대시보드를 구축합니다.
2. **추론/평가 스크립트 분리**: `scripts/evaluate_transformer.py`를 추가해 배포 전 품질 검증을 자동화합니다.
3. **실험 추적**: MLflow 또는 W&B를 붙여 모델 버전, 하이퍼파라미터, 지표를 중앙에서 관리합니다.
4. **패키지화/CI**: `pyproject.toml` 추가, pytest 기반 CI 파이프라인으로 코드 품질을 지속 검증합니다.
5. **서빙 고려**: FastAPI 엔드포인트 혹은 배치 추론 스크립트를 준비해 운영 환경으로의 연계를 단순화합니다.

## 참고 명령어
```bash
# 전체 파이프라인 실행
python scripts/run_all.py

# Transformer 단독 학습
python -m scripts.train_transformer

# Baseline 비교
python -m scripts.train_baseline
```

문서 내용은 모델/데이터 변경 시마다 갱신하여 파이프라인 지식이 팀 전체에 공유되도록 유지해 주세요.
