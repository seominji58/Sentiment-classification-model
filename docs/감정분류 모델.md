# 🎯 Saegim Emotion Classification Pipeline Guide

## 🧩 프로젝트 목적

- 감성대화 데이터(`merged.csv`)를 기반으로 5개 감정(행복/평온/불안/분노/슬픔)을 분류하는 모델을 학습한다.
    
- Colab 의존을 제거하고, Cursor IDE에서 **파일 기반 구조**로 안정적이고 재현 가능한 파이프라인을 만든다.
    

---

## 📂 폴더 구조 설계

emotion-model/  
│  
├── data/  
│ ├── merged.csv # 전체 데이터 (text + label)  
│ └── splits/  
│ ├── train.csv  
│ └── valid.csv  
│  
├── src/  
│ ├── __init__.py  
│ ├── utils.py  
│ ├── data_io.py  
│ ├── preprocess.py  
│ ├── label_map.py  
│ ├── split.py  
│ ├── anomaly.py  
│ ├── baseline.py  
│ ├── transformer.py  
│ └── evaluation.py  
│  
├── configs/config.json  
│  
├── processed/  
│ ├── cleaned.csv  
│ ├── label_mapping.json  
│ ├── splits/  
│ ├── train.csv  
│ └── valid.csv  
│ └── models/  
│ ├── baseline/  
│ └── transformer/  
│  
├── scripts/  
│ ├── run_all.py  
│ ├── train_baseline.py  
│ ├── train_transformer.py  
│ └── check_anomaly.py  
│  
├── requirements.txt  
└── PIPELINE_GUIDE.md

---

## ⚙️ 실행 환경

- **Python:** 3.11
    
- **IDE:** Cursor / VS Code
    
- **가상환경:** Miniconda 권장
    

명령어 예시:  
`conda create -n saegim python=3.11 -y`  
`conda activate saegim`  
`pip install -r requirements.txt`

필요 패키지:  
`pandas scikit-learn transformers torch datasets joblib tqdm`

---

## 🧠 개발 원칙

**변수명 일관성:**  
`merged_df → cleaned_df → final_df → train_df / valid_df`

**단계별 유효성 체크 (필수):**

- `assert {'text','label'}.issubset(df.columns)`
    
- `assert len(df) > 0`
    
- 저장 후: `파일 크기 확인`
    

**라벨 매핑 단일 진실원 (Single Source of Truth):**  
모든 매핑은 `configs/config.json`에서 로드한다.

예시:  
`{ "label_mapping": { "기쁨": "행복", "당황": "불안", "분노": "분노", "상처": "슬픔", "슬픔": "슬픔", "중립": "평온" } }`

---

## 🚀 파이프라인 단계

|단계|모듈|기능|입력|출력|
|---|---|---|---|---|
|1️⃣|data_io.py|CSV 로드, 파일 검증|merged.csv|merged_df|
|2️⃣|preprocess.py|텍스트 정제 및 중복/결측 제거|merged_df|cleaned_df|
|3️⃣|label_map.py|6→5 감정 매핑 및 검증|cleaned_df|final_df|
|4️⃣|split.py|Stratified 90/10 분할|final_df|train.csv, valid.csv|
|5️⃣|anomaly.py|TF-IDF 기반 이상치 탐지|train.csv|anomaly_samples.csv|
|6️⃣|baseline.py|TF-IDF + LinearSVC 학습|train/valid|metrics.json|
|7️⃣|transformer.py|HuggingFace Trainer 기반 모델|train/valid|best model|
|8️⃣|evaluation.py|Macro-F1, Confusion Matrix 계산|valid|metrics.json|

---

## 🔒 유틸 (`src/utils.py`)

- 단계 통과 표시: `mark_ok(step)`
    
- 단계 요구 확인: `require(step)`
    
- 결측/빈 데이터 검증: `must_have_cols(df, cols)`, `must_not_empty(df)`
    
- CSV 저장 시 파일 크기 확인 필수
    
- 로그: `log_step(name, **stats)`
    

---

## 🧩 실행 순서 (`scripts/run_all.py`)

1. `merged_df = data_io.load_merged("data/merged.csv")`
    
2. `cleaned_df = preprocess.clean(merged_df)`
    
3. `final_df = label_map.apply_mapping(cleaned_df, "configs/config.json")`
    
4. `train_df, valid_df = split.make_splits(final_df, 0.1)`
    
5. `anomaly.check_labels(train_df)`
    
6. `baseline.train_and_evaluate(train_df, valid_df)`
    
7. `transformer.train(train_df, valid_df)`
    

---

## 📈 평가 지표

- Accuracy
    
- Macro F1 Score
    
- Confusion Matrix
    
- Class Precision / Recall
    

저장 경로:

- `processed/models/baseline/metrics.json`
    
- `processed/models/transformer/metrics.json`
    

---

## 📜 개발 주의 요약

1. 라벨 매핑은 반드시 config에서 로드.
    
2. 전제조건 불만족 시 즉시 중단 (`RuntimeError`).
    
3. 파일 저장 후 반드시 크기 검증.
    
4. 오류는 명확히 raise.
    
5. `python scripts/run_all.py` 한 번으로 전체 실행 가능해야 함.
    

---

## ✅ 완성 기준

- 모든 단계가 오류 없이 통과.
    
- `processed` 내부에 산출물 생성.
    
- Transformer의 Macro-F1 ≥ Baseline.
    
- 동일 데이터로 재현 가능.
    

---

## ⚠️ ADDENDUM (Pipeline Tips)

- 전처리는 split 이전에만 수행.
    
- 라벨 매핑은 `config.json` 단일 진실원에서 로드.
    
- Stratified Split 실패 시 폴백 옵션 `--allow-random-split`.
    
- TF-IDF는 `char_wb (3~5)` 추천.
    
- Transformer는 `klue/roberta-base`, macro-F1 기준 early stopping.